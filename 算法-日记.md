<h2>16年5月24</h2>
<h3>下午3点22</h3>
今天开始复习基础的算法<br>
算法主要是学习算法的思想，思想可以用到很多问题的解决思路上，不要局限与代码的实现。<br>
具体代码的实现要结合不同的数据结构来做。<br>
<h2>贪心算法</h2>
贪心算法是不能联机处理数据的，这样算法不知道数据的整体情况，得不到最优解！！<br>
<br>
贪心算法在应用前要先证明整体最优解是有局部最优解而的来，否则，算法得不到问题的最优解。<br>
但是贪心算法比较简单，编程也简单。。。<br>
寻找图的单源最短路径（dijkstra算法等）和最小生成树（prime算法等）都是用的贪心思想<br>
<br>
要看问题是否能用贪心算法解决，是要看该问题是否有贪心选择性质和最优子结构性质：<br>
贪心选择性质是说整个问题的最优解是可以用几个局部最优解得到。贪心是自顶向下解决问题（动态规划是自底向上）。<br>
&emsp;&emsp;每进行一次贪心选择，就把问题变为更小的子问题解决。<br>
最优子结构性质是说，整体问题的最优解是可以推导出子问题的局部最优解的。<br>
<br>
所以说贪心算法能解决背包问题，但是不能解决0-1背包问题（区别就是：背包问题是可以装入某件物品的一部分，而0-1不能）<br>
<br>
解释一下为什么0-1背包问题不满足贪心选择性质：<br>
&emsp;&emsp;因为该问题的局部最优解不能导致整体的最优解（这是废话哈，跟不满足性质是一个意思。。。）<br>
&emsp;&emsp;当每一步选择当前局部最优解的解决方案时，并不能保证背包是会被装满的<br>
&emsp;&emsp;如果不能被装满的话，最后的背包的单位空间内负载的价值就不是最优的。<br>
&emsp;&emsp;也就是说，这一步的最优解和下一步的最优解可能是冲突的，（这一步的非最优解可能导致下一步的最优解）<br>
&emsp;&emsp;这就不满足贪心选择性质和最优子结构性质。。。<br>
<br>
<h3>贪心算法的几种情况：</h3>
1.活动时间排序问题。<br>
&emsp;&emsp;有n个活动，每个活动有自己的开始时间start[n]和结束时间finish[n]。这些活动都要共用一个场地（资源）<br>
那么怎么安排才能使这些活动中举行的活动数量最多。<br>
这时就用贪心算法，首先要把活动按照结束时间排序（非递减），每次选择结束时间最早，但又不与已经计划的活动时间冲突的活动<br>
这样算法，安排活动时间复杂度为O(n)，排序要花O(nlog(n))<br>
<br>
2.哈夫曼编码问题。<br>
&emsp;&emsp;对文件的压缩处理。<br>
&emsp;&emsp;根据文件中某个字符（单词）的出现次数进行0-1字符串编码，出现次数少的码长要较长，多的要较少。<br>
&emsp;&emsp;背景如上所述。。。<br>
&emsp;&emsp;哈夫曼编码的解决方案是：把每个字符（单词）构成一棵树，这样一个文档就生成了一个森林。<br>
每次选取出现次数最少的两棵树合并成一棵树，，这颗树的次数是两颗子树的次数之和。每次都这样做，知道森林中只有一棵树<br>
平均码长的定义为：Σ(f*l)，f是字符（单词）的出现频率，l是编码码长。<br>
哈夫曼编码得到的平均码长是最短的，即为最优解<br>
<br>
我只能感性的感觉哈夫曼编码是满足贪心选择和最优子结构性质的，具体怎么证明。。还有待查资料。。。<br>
<br>
3.图的单源最短路径和最小生成树。<br>
&emsp;&emsp;见《图-日记.md》<br>
<br>
<br>
<h3>晚上22:00</h3>
晚上处理了一些小问题，继续搞算法。。<br>
<h3>分治算法</h3>
分治算法的核心思想是把大问题分解成小问题，这样容易解决，解决之后在合并为整体问题的解。<br>
能用分治算法解决的问题的特征是：<br>
&emsp;&emsp;大问题能分解成小问题，大问题的最优解能推到出小问题的最优解（即有最优子结构）。<br>
&emsp;&emsp;各个小问题之间是相互独立的，互不影响。<br>
&emsp;&emsp;各个小问题中没有重叠的子问题。（这点是与动态规划的区别。。。）<br>
&emsp;&emsp;而且当问题缩小到一定规模之后能很容易的解决。<br>
分治算法与贪心算法的区别：<br>
&emsp;&emsp;贪心是一步一步的搭建最优解，而分治算法是每次解决一个最小问题的最优解，最后合并成大问题最优解。<br>
&emsp;&emsp;贪心过程中，如果有一点没有达到局部最优解，则以后的过程全不是最优解。而分治中，某个小问题不是最优解，其他的部分也可以是最优解。<br>
<br>
用分治解决问题的步骤：<br>
主要是数学归纳法找到问题的求解方程。<br>
1.找到最小规模的问题，并找到解决方法。<br>
2.找到小问题合并成大问题的方法。<br>
3.设计递归过程。<br>
<br>
<br>
<br>
插入一个另外的东西，虽然分治算法可以有效的在O(nlog(n))时间内解决最大连续子数组和的问题。<br>
但是该问题还有更好的解决方法，可以在O(N)的时间内解决掉。<br>
当已经有了前（i-1）个数的最大连续子数组和时，扫描到第i个数后，要么包括i点，要么只有i点，要么就还是原来的子数组。<br>
so，设置两个变量：max_here，max_so_far。<br>
&emsp;&emsp;max_here保存的是前两种情况的最大值（包括i点，只有i点）。这样设置是为了在循环时max_here中保存的值对应的数组都是连续的，不会出现中间有间隔的情况。。。<br>
&emsp;&emsp;max_so_far保存的是迄今为止的整体最大连续子数组和，每次循环时，改变量都与max_here比较，保存最大值。<br>
&emsp;&emsp;两个变量的初始化：若数组中有非负数，则初始化为0；若全是负数，则初始化为数组中的最小值。<br>
这样循环一趟数组就可以得出结果了。。。<br>
<br>
然后求数组逆序对问题：快速排序中进行多少次的元素交换，就有多少个的逆序对。所以过程和快排一样，只是多加了一步统计而已。<br>
用分治法求解大数相乘问题，简直就是折腾字符串啊，，太折腾了。。。<br>
写了一个超级简单的demo，就不传到github上了。。。~>_<~...<br>
<br>
<h2>16年5月25</h2>
<h3>下午5:20</h3>
<h3>动态规划--简称DP（Dynamic Programming）</h3>
开始折腾动态规划了。。。<br>
动态规划是自底向上的求解问题，把每一个小问题的解都存储起来，当上面调用的时候，直接调用结果就好，就不用再去求解一遍小问题了，这样有效的改进了递归程序中的多余的运算。。。<br>
很多情况下，递归方法肯定不是最好的。。。<br>
动态规划的思想其实可以在很多地方应用。<br>
比如：在高并发的服务器中加入缓存就是用了这种思想，已经处理过的结果放入缓存，下次来query时，直接命中缓存<br>
(上面好像纯属瞎说。。。。)<br>
动态规划的重点是确定各种状态的转移过程，把问题划分为各个阶段，确定各个阶段的状态，推导出各个状态之间的转移过程。<br>
感觉分析状态转移的过程有点像马尔科夫链。。。<br>
写了一个凑硬币的小程序，用的动态规划，这种状态确定和转移的思想还有这种思想到程序的落实还是值得思考的！<br>
程序放在了DP_coins.cpp<br>
<br>
区分两问题：<br>
&emsp;&emsp;1.求一个序列中的最长非递减子序列长度，这里面的子序列可以是不连续的，那么求解的时候以第i个元素结尾的最长非递减子序列的长度是和以前的所有元素（状态）有关的，把前面比它小的元素的状态值的最大值加一就是该状态。<br>
&emsp;&emsp;2.求一个序列中最长连续子序列的长度，这个问题中以每个元素结尾的最长连续子序列的大小（状态）就只与上一个状态有关，和其他状态无关。若上一个元素小于等于该元素，则把上一个状态加一就是该状态，否则该状态就是一。<br>
<br>
看到一个解决1.问题（不连续）的很不错的算法，可以把时间压缩到O(nlog(n))。<br>
参考博客<a href="https://www.felix021.com/blog/read.php?1587">最长递增子序列 O(NlogN)算法 </a><br>
理解两个重点：<br>
1.另分出去的数组存储的并不是LIS（最长递增子序列），而是对应的LIS大小的最小末尾值，假如B[3]=5，说明长度为3的递增子序列的最小末尾值是5。这样看以后元素在该数组的插入位置就能知道那时的LIS值是多少了。<br>
2.卧槽。。突然忘了是啥重点了。。想起来再写在这。。。<br>
<br>
<h3>找到一个很有意思的DP问题</h3>
无向图G有N个结点，它的边上带有正的权重值。<br>
你从结点1开始走，并且一开始的时候你身上带有M元钱。如果你经过结点i，那么你就要花掉S[i]元(可以把这想象为收过路费)。<br>
如果你没有足够的钱， 就不能从那个结点经过。<br>
在这样的限制条件下，找到从结点1到结点N的最短路径(经过此路径，钱数能够到达N点),或者输出该路径不存在。<br>
如果存在多条最短路径，那么输出花钱数量最少的那条。<br>
<br>
我的刚开始的思考是，可以先生成该图的最小生成树，然后在找到从源顶点到目的顶点花的钱数，如果还有余钱，则可以到达，否则不能到达<br>
或者把某个顶点的过路费当做到达该顶点的边的权值，以此生成最小生成树，然后找到最小路径。<br>
但是仔细思考一下，上述两种思路都不能成立！！<br>
因为路径的长度和花费的钱数是两个独立的变量，它俩不存在因果的关系。而且上述那样做的话，会砍掉了很多种情况，那么自然导致的结果就不可能是问题的解。。。<br>
这个问题可以用DP来解决，具体思路为：<br>
PS:终于明白我的上述想法为什么是错的了！！！<br>
&emsp;&emsp;因为我只是把从某顶点到另一个顶点的最短路径想成了只有一个，其实最短路径可能有好多个，但是从这些最短路径经过时花费的钱是不相同的！！！<br>
&emsp;&emsp;所以这时候必须要用二维数组来保存最短路径，一维是顶点标号，一维是剩余的钱数。<br>
&emsp;&emsp;当找到最短路径时，要保存当时的最短路径长度和剩余的钱数，这样表示：M[i][j]=s，意思是说：到达顶点i的最短路径为s，从这个最短路径到达i点所剩余的钱数为j！！！<br>
<br>
具体步骤等明天在思考了。。。<br>
(哎呀,卧槽，，抽根烟想算法的效率就是高啊。。。哈哈)<br>
<h3>16年5月26</h3>
整个流程和dijkstra算法差不多，只不过在“松弛”过程中增加了更新路费的过程，把小于等于当前最短路径长度的路费更新到该顶点。<br>
其实也可以用一维数组来解决问题，vector<node> list中的节点list[i]保存了i节点的最小路径和最小路径对应的最小路费。<br>
这样的一维数组还避免了路费不是整数的问题。。。<br>
我觉得这个问题应该以路径最小为主，其次找最小路径长度下的最小费用。<br>
也就是说只要“松弛”的路径比当前路径短，就更新路径长度和费用。“松弛”的路径和当前路径一样，如果费用少就更新费用！<br>
所以整个算法的时间复杂度就是dijkstra算法的时间复杂度，用Fibonacci堆的话为O(nlog(n))；<br>
node中的存储格式：vector<node*> childs保存节点的若干孩子节点指针。<br>
&emsp;&emsp;&emsp;&emsp;double path保存最短路径长度<br>
&emsp;&emsp;&emsp;&emsp;double fee 保存最短路径长度下的最短费用。<br>
同时还要有一个数组保存所有的图节点，还要有一个二维数组保存所有的边。<br>
但是一切“松弛”更新以能够到达i点为前提，就是说，如果考虑i点后路费已经不够（小于0），则不再比较路径和费用的大小。<br>
而且在算法中，已经标记处理过的顶点（marked==true）也要在经过松弛过程，只是不再作为下一个处理顶点了（不再压入队列）。<br>
<br>
旅游信息在磁盘中存储的格式：<br> 
第一行存储旅游资金数额。和顶点个数<br>
下面每一行存储一个顶点的信息：顶点编号 名称 路费数额 邻接的顶点个数 然后是每个邻接顶点的编号和路径长度。<br>
<br>
在内存中就用临界表存储<br>
<br>
按照上述思路写了一个小程序，放在了DP_travel.cpp中。。。<br>
写了一个很简单的捡苹果问题的程序，以此程序结束对动态规划的复习<br>
问题是：有一个格子田，每个格子里面存有一些数量的苹果，没走到一个格子里都要把里面的苹果捡起来，而且是捡光。<br>
&emsp;&emsp;&emsp;&emsp;那么一个人从格子田的左上角走到右下角，最多能捡多少个苹果？<br>
代码放在了DP_apple.cpp里面<br>
从这个题可以简单的分析一下DP问题的结题思路。状态的转移，走到每一个格子里的最大苹果数都是依赖它的上一个格子和左边的格子的最大苹果数。所以是一行一行、一列一列的分析的。<br>
会分析DP状态，DP问题就很清楚了。编程是很简单的<br>
<br>
<h3>晚上8:16</h3>
DP还不能结束！！又看见一个有意思的问题，用DP求最优的二叉查找树！<br>
所谓最优是指用这颗查找树查找元素时，平均节点的访问次数最少。<br>
需求的详细描述是这样的：有一系列元素，每个元素有一个先验的查找概率Pi，概率大的元素会被经常访问，小的访问频率小。<br>
&emsp;&emsp;&emsp;&emsp;那么怎么生成二叉查找树，才能使查找元素时平均访问的节点数最少。<br>
<br>
<img src="http://pic002.cnblogs.com/images/2012/382323/2012042609203545.png"/><br>
如上图所示，C(i,j)为i，j之间所有元素的平均最小访问次数。<br>
所以这个问题是由小问题叠加上去的，可以用DP方法来解决。<br>
可以用一个二维数组来保存c(i,j)的值，对角线的元素c(i,i)为Pi，而c(i,j)=0，当(i>j)时<br>
其他地方的值都是由子结构得到的。但是每次找最优根节点是一个遍历的事，每次都要把i，j中间的所有元素都尝试一遍，计算最小的c(i,j)的值，得到最优的根节点。<br>
最后结果就是从最后一步得到的最优根节点递归的得到下面的子树根节点（(i,k)，(k,j)）。<br>
这个问题只能沿着二维数组的对角线向后移动，也就是斜着向后进行，因为每一次都需要前面的数据，而且是行前面的和列前面的都需要，所以不能一行一行的进行，这些小细节要注意。。。<br>
<h3>还有个有意思的问题：所有点对的最短路径</h3>
在一个有向图中，求所有点对之间的最短路径。<br>
在求一个源点对所有点的最短路径时（单源），可以用dijkstra算法，但是在求任意点对时，不能进行N次dijkstra算法，时间复杂度太高。。。<br>
可以用DP方法实现，受dijkstra算法启发（经过中间层的路径“松弛”），每次求i点经过（1,2,3...k）点到达j点的（i，j）最小路径，k从1到N。这样就求出了考虑所有中间点情况时的（i，j）最短路径。。。迭代三重循环就能求出任意点对之间的最短路径。<br>
L(i,j)=min(d(i,j),L(i,k)+L(k,j))，其中L(i,j)为i,j的最短路径，d(i,j)为i,j的直接距离。<br>
但是还不知道怎么保存任意两点之间最短距离所经过的序列。。。<br>
<br>
想明白怎么保存路径了，和上一个问题相似！！<br>
在每一次更新路径长度时，保存中间的k值Path[i][j]=k。当最后求i,j的路径序列时，只需递归的求k值就可以了！！<br>
DP真是个牛逼的思维！！很多问题用DP解决，思路都很简单清晰。。。<br>
<br>
DP就暂时告一段落了，看一看随机算法<br>
<br>
<h3>随机化算法</h3>
随机化算法在数值计算，模拟行为，自然环境建模等方面的用处很大。主要就是用生成随机数来解决确定性算法不能解决的问题！<br>
算法分为确定的和非确定的：<br>
&emsp;&emsp;确定性算法有传统算法：以100%成功概率求问题的最优解。<br>
&emsp;&emsp;&emsp;&emsp;近似算法：一种对解质量的让步。<br>
&emsp;&emsp;非确定算法有随机算法：一种对成功概率和解质量的让步。但是时间复杂度很低<br>
&emsp;&emsp;&emsp;&emsp;智能算法：遗传算法、模拟退火、拟人拟物算法等。<br>
